# H∆∞·ªõng d·∫´n: ChatAI hi·ªÉu v√† truy xu·∫•t th√¥ng tin t·ª´ rag_documents

## üìö T·ªïng quan

H·ªá th·ªëng RAG (Retrieval-Augmented Generation) cho ph√©p ChatAI hi·ªÉu v√† tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin trong b·∫£ng `rag_documents` c·ªßa SQL Server. Qu√° tr√¨nh n√†y ho·∫°t ƒë·ªông qua 3 b∆∞·ªõc ch√≠nh:

1. **Ingest (Nh·∫≠p li·ªáu)**: Chuy·ªÉn ƒë·ªïi t√†i li·ªáu PDF th√†nh embeddings v√† l∆∞u v√†o database
2. **Retrieval (Truy xu·∫•t)**: T√¨m ki·∫øm c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan nh·∫•t v·ªõi c√¢u h·ªèi
3. **Generation (T·∫°o c√¢u tr·∫£ l·ªùi)**: S·ª≠ d·ª•ng LLM (Gemini) ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n context

---

## üîÑ Quy tr√¨nh ho·∫°t ƒë·ªông chi ti·∫øt

### B∆∞·ªõc 1: Ingest Documents (Nh·∫≠p li·ªáu)

Khi b·∫°n ch·∫°y `POST /ingest`, h·ªá th·ªëng s·∫Ω:

#### 1.1. Load PDF files
```python
# Qu√©t t·∫•t c·∫£ file PDF trong th∆∞ m·ª•c ./data
loader = PyPDFDirectoryLoader(str(self.data_dir))
documents = loader.load()
```

#### 1.2. Chia nh·ªè th√†nh chunks
```python
# Chia m·ªói document th√†nh c√°c ƒëo·∫°n nh·ªè (chunks)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,      # M·ªói chunk ~1000 k√Ω t·ª±
    chunk_overlap=100      # Overlap 100 k√Ω t·ª± gi·ªØa c√°c chunks
)
chunks = text_splitter.split_documents(documents)
```

**T·∫°i sao c·∫ßn chia nh·ªè?**
- LLM c√≥ gi·ªõi h·∫°n ƒë·ªô d√†i input
- Chia nh·ªè gi√∫p t√¨m ki·∫øm ch√≠nh x√°c h∆°n
- Overlap gi√∫p kh√¥ng m·∫•t th√¥ng tin ·ªü ranh gi·ªõi

#### 1.3. T·∫°o Embeddings (Vector h√≥a)

M·ªói chunk ƒë∆∞·ª£c chuy·ªÉn th√†nh m·ªôt **embedding vector** (m·∫£ng s·ªë th·ª±c):

```python
# V√≠ d·ª•: "M√°y b∆°m c√≥ c√¥ng su·∫•t 5HP"
# ‚Üí Embedding: [-0.069, -0.024, 0.028, ..., 0.145] (384 s·ªë)
```

**Embedding l√† g√¨?**
- L√† bi·ªÉu di·ªÖn s·ªë h·ªçc c·ªßa vƒÉn b·∫£n
- C√°c vƒÉn b·∫£n c√≥ nghƒ©a t∆∞∆°ng t·ª± s·∫Ω c√≥ vector g·∫ßn nhau
- Cho ph√©p t√¨m ki·∫øm theo ng·ªØ nghƒ©a (semantic search)

**C√≥ 2 c√°ch t·∫°o embeddings:**

**Option A: SQL Server AI_GENERATE_EMBEDDINGS**
```sql
SELECT AI_GENERATE_EMBEDDINGS(@text USE MODEL local_onnx_embeddings)
```
- S·ª≠ d·ª•ng ONNX model trong SQL Server
- Kh√¥ng c·∫ßn Python API

**Option B: Python API**
```python
POST http://localhost:5005/vectorize
{
  "texts": ["M√°y b∆°m c√≥ c√¥ng su·∫•t 5HP"]
}
```
- Linh ho·∫°t h∆°n, c√≥ th·ªÉ d√πng nhi·ªÅu models

#### 1.4. L∆∞u v√†o SQL Server

```sql
INSERT INTO dbo.[rag_documents] 
(Content, VectorJson, Embedding, FileName, PageNumber, ChunkIndex)
VALUES 
('M√°y b∆°m c√≥ c√¥ng su·∫•t 5HP...', 
 '[-0.069, -0.024, ...]',  -- JSON backup
 CAST('[0.069, 0.024, ...]' AS VECTOR(384)),  -- Native VECTOR type
 'manual.pdf', 
 5, 
 12)
```

**C·∫•u tr√∫c b·∫£ng:**
- `Content`: VƒÉn b·∫£n g·ªëc (NVARCHAR(MAX))
- `Embedding`: Vector embedding (VECTOR(384)) - SQL Server 2025
- `VectorJson`: Backup d·∫°ng JSON (NVARCHAR(MAX))
- `FileName`: T√™n file ngu·ªìn
- `PageNumber`: S·ªë trang trong PDF
- `ChunkIndex`: Th·ª© t·ª± chunk

---

### B∆∞·ªõc 2: Chat - Retrieval (Truy xu·∫•t)

Khi user h·ªèi: **"M√°y b∆°m c√≥ c√¥ng su·∫•t bao nhi√™u?"**

#### 2.1. Generate embedding cho query

```python
# Chuy·ªÉn c√¢u h·ªèi th√†nh vector
query = "M√°y b∆°m c√≥ c√¥ng su·∫•t bao nhi√™u?"
query_vector = generate_embedding(query)
# ‚Üí [-0.071, -0.025, 0.029, ..., 0.142]
```

#### 2.2. Vector Similarity Search

H·ªá th·ªëng t√¨m c√°c chunks c√≥ embedding **g·∫ßn nh·∫•t** v·ªõi query vector:

```sql
SELECT TOP (4)
    ID,
    Content,
    FileName,
    PageNumber,
    ChunkIndex,
    (1.0 - VECTOR_DISTANCE(
        Embedding, 
        CAST(@queryVector AS VECTOR(384)), 
        COSINE
    )) AS Similarity
FROM dbo.[rag_documents]
WHERE Embedding IS NOT NULL
ORDER BY VECTOR_DISTANCE(
    Embedding, 
    CAST(@queryVector AS VECTOR(384)), 
    COSINE
) ASC
```

**VECTOR_DISTANCE ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?**
- T√≠nh kho·∫£ng c√°ch gi·ªØa 2 vectors b·∫±ng **Cosine Similarity**
- Cosine Similarity = 1.0 ‚Üí Gi·ªëng nhau ho√†n to√†n
- Cosine Similarity = 0.0 ‚Üí Kh√°c nhau ho√†n to√†n
- ORDER BY ASC ‚Üí L·∫•y nh·ªØng vector g·∫ßn nh·∫•t (kho·∫£ng c√°ch nh·ªè nh·∫•t)

**V√≠ d·ª• k·∫øt qu·∫£:**
```
ID  | Content                          | Similarity | FileName
----|----------------------------------|------------|----------
19  | M√°y b∆°m Model X c√≥ c√¥ng su·∫•t 5HP | 0.92       | manual.pdf
23  | Th√¥ng s·ªë k·ªπ thu·∫≠t m√°y b∆°m: 5HP   | 0.88       | manual.pdf
31  | C√¥ng su·∫•t: 5HP, ƒëi·ªán √°p: 220V    | 0.85       | spec.pdf
```

#### 2.3. L·∫•y Top-K chunks

H·ªá th·ªëng l·∫•y top 4 chunks c√≥ similarity cao nh·∫•t ƒë·ªÉ l√†m context.

---

### B∆∞·ªõc 3: Generation (T·∫°o c√¢u tr·∫£ l·ªùi)

#### 3.1. T·∫°o Prompt v·ªõi Context

```python
context = """
[manual.pdf, trang 5]: M√°y b∆°m Model X c√≥ c√¥ng su·∫•t 5HP...
[manual.pdf, trang 6]: Th√¥ng s·ªë k·ªπ thu·∫≠t m√°y b∆°m: 5HP...
[spec.pdf, trang 2]: C√¥ng su·∫•t: 5HP, ƒëi·ªán √°p: 220V...
"""

prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh. H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n c√°c ƒëo·∫°n vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.

Context (c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan):
{context}

C√¢u h·ªèi: {query}

H∆∞·ªõng d·∫´n:
- Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n th√¥ng tin c√≥ trong context
- N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin trong context, h√£y n√≥i r√µ "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin n√†y trong t√†i li·ªáu"
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát n·∫øu c√¢u h·ªèi l√† ti·∫øng Vi·ªát
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu

C√¢u tr·∫£ l·ªùi:"""
```

#### 3.2. G·ªçi LLM (Gemini)

```python
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-flash",
    google_api_key=api_key,
    temperature=0.7
)

answer = llm.invoke(prompt)
```

**Gemini s·∫Ω:**
- ƒê·ªçc context t·ª´ c√°c chunks li√™n quan
- Hi·ªÉu c√¢u h·ªèi c·ªßa user
- T·ªïng h·ª£p th√¥ng tin v√† t·∫°o c√¢u tr·∫£ l·ªùi
- Ch·ªâ d·ª±a v√†o context, kh√¥ng t·ª± b·ªãa ƒë·∫∑t

#### 3.3. Tr·∫£ v·ªÅ k·∫øt qu·∫£

```json
{
  "answer": "Theo t√†i li·ªáu, m√°y b∆°m c√≥ c√¥ng su·∫•t 5HP. Th√¥ng tin n√†y ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong manual.pdf (trang 5) v√† spec.pdf (trang 2).",
  "sources": [
    {
      "file_name": "manual.pdf",
      "page_number": 5,
      "content_preview": "M√°y b∆°m Model X c√≥ c√¥ng su·∫•t 5HP..."
    },
    {
      "file_name": "spec.pdf",
      "page_number": 2,
      "content_preview": "C√¥ng su·∫•t: 5HP, ƒëi·ªán √°p: 220V..."
    }
  ],
  "query": "M√°y b∆°m c√≥ c√¥ng su·∫•t bao nhi√™u?"
}
```

---

## üéØ T·∫°i sao RAG hi·ªáu qu·∫£?

### 1. Semantic Search (T√¨m ki·∫øm ng·ªØ nghƒ©a)

Kh√¥ng ch·ªâ t√¨m ki·∫øm t·ª´ kh√≥a, m√† hi·ªÉu **√Ω nghƒ©a**:

**V√≠ d·ª•:**
- Query: "C√¥ng su·∫•t m√°y b∆°m?"
- T√¨m ƒë∆∞·ª£c: "M√°y b∆°m Model X c√≥ c√¥ng su·∫•t 5HP"
- D√π kh√¥ng c√≥ t·ª´ "c√¥ng su·∫•t" trong query, nh∆∞ng embedding hi·ªÉu ƒë∆∞·ª£c nghƒ©a t∆∞∆°ng t·ª±

### 2. Context-Aware (Nh·∫≠n th·ª©c ng·ªØ c·∫£nh)

LLM nh·∫≠n ƒë∆∞·ª£c **context c·ª• th·ªÉ** t·ª´ database, kh√¥ng ph·∫£i d·ª±a v√†o training data c≈©:

- ‚úÖ Tr·∫£ l·ªùi ch√≠nh x√°c v·ªÅ th√¥ng tin trong t√†i li·ªáu
- ‚úÖ C√≥ th·ªÉ tr·∫£ l·ªùi v·ªÅ th√¥ng tin m·ªõi nh·∫•t
- ‚úÖ Kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin kh√¥ng c√≥ trong context

### 3. Traceable (C√≥ th·ªÉ truy v·∫øt)

M·ªói c√¢u tr·∫£ l·ªùi ƒë·ªÅu c√≥ **sources**:
- Bi·∫øt ƒë∆∞·ª£c th√¥ng tin l·∫•y t·ª´ file n√†o
- Bi·∫øt ƒë∆∞·ª£c trang n√†o trong PDF
- C√≥ th·ªÉ ki·ªÉm tra l·∫°i ngu·ªìn g·ªëc

---

## üîå T√≠ch h·ª£p v·ªõi Frontend

### C√°ch 1: G·ªçi tr·ª±c ti·∫øp Python RAG API

```typescript
// Trong chat.service.ts
sendMessageToRAG(query: string): Observable<ChatResponse> {
  const headers = new HttpHeaders({
    'Content-Type': 'application/json'
  });

  return this.http.post<ChatResponse>(
    'http://localhost:8000/chat',
    { query },
    { headers }
  );
}
```

### C√°ch 2: T√≠ch h·ª£p v√†o Firebase Function

C√≥ th·ªÉ t·∫°o Firebase Function wrapper ƒë·ªÉ g·ªçi Python RAG API:

```javascript
// functions/src/index.ts
export const chatFunction = functions.https.onRequest(async (req, res) => {
  const { query } = req.body;
  
  // G·ªçi Python RAG API
  const ragResponse = await axios.post('http://localhost:8000/chat', {
    query
  });
  
  // Tr·∫£ v·ªÅ k·∫øt qu·∫£
  res.json({
    answer: ragResponse.data.answer,
    sources: ragResponse.data.sources
  });
});
```

---

## üìä V√≠ d·ª• th·ª±c t·∫ø

### Scenario: User h·ªèi v·ªÅ "Chuy·ªÉn ƒë·ªïi s·ªë"

**Query:** "FPT c√≥ nh·ªØng ch∆∞∆°ng tr√¨nh chuy·ªÉn ƒë·ªïi s·ªë n√†o?"

**B∆∞·ªõc 1: Generate embedding**
```
Query: "FPT c√≥ nh·ªØng ch∆∞∆°ng tr√¨nh chuy·ªÉn ƒë·ªïi s·ªë n√†o?"
‚Üí Vector: [-0.052, 0.031, -0.018, ..., 0.127]
```

**B∆∞·ªõc 2: Vector Search**
```sql
-- T√¨m top 4 chunks li√™n quan
SELECT TOP 4 Content, Similarity
FROM rag_documents
ORDER BY VECTOR_DISTANCE(...) ASC
```

**K·∫øt qu·∫£:**
```
1. "C√°c ch∆∞∆°ng tr√¨nh h√†nh ƒë·ªông c√≥ th·ªÉ ƒë∆∞·ª£c gi..." (Similarity: 0.91)
2. "FPT ƒë·ªÅ xu·∫•t d·ª± ki·∫øn chi ph√≠ tr√™n c∆° s·ªü ki..." (Similarity: 0.87)
3. "Thi·∫øt l·∫≠p nh√≥m CƒêS t·∫°i THIBIDI gi√∫p l√†m r..." (Similarity: 0.84)
4. "Ph∆∞∆°ng th·ª©c tri·ªÉn khai ph√π h·ª£p v·ªõi l·ªô tr√¨..." (Similarity: 0.81)
```

**B∆∞·ªõc 3: Generate Answer**
```
Context: [4 chunks li√™n quan v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë]

Answer: "Theo t√†i li·ªáu, FPT c√≥ c√°c ch∆∞∆°ng tr√¨nh chuy·ªÉn ƒë·ªïi s·ªë bao g·ªìm:
- Thi·∫øt l·∫≠p nh√≥m CƒêS t·∫°i THIBIDI
- C√°c ch∆∞∆°ng tr√¨nh h√†nh ƒë·ªông c·ª• th·ªÉ
- Ph∆∞∆°ng th·ª©c tri·ªÉn khai ph√π h·ª£p v·ªõi l·ªô tr√¨nh

Th√¥ng tin chi ti·∫øt ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p trong c√°c t√†i li·ªáu n·ªôi b·ªô c·ªßa FPT."
```

---

## üõ†Ô∏è C·∫•u h√¨nh v√† T·ªëi ∆∞u

### 1. TƒÉng ƒë·ªô ch√≠nh x√°c

**TƒÉng s·ªë chunks (top_k):**
```python
result = service.chat(query, top_k=8)  # Thay v√¨ 4
```

**Gi·∫£m chunk_size ƒë·ªÉ chia nh·ªè h∆°n:**
```python
rag_service = RAGServiceSQL(
    chunk_size=500,  # Thay v√¨ 1000
    chunk_overlap=50
)
```

### 2. TƒÉng t·ªëc ƒë·ªô

**T·∫°o Vector Index:**
```sql
CREATE VECTOR INDEX IX_rag_documents_Embedding 
ON dbo.[rag_documents] (Embedding) 
WITH (INDEX_TYPE = HNSW, DISTANCE_FUNCTION = COSINE);
```

**Gi·∫£m embedding dimension (n·∫øu c√≥ th·ªÉ):**
```python
embedding_dimension=256  # Thay v√¨ 384 (nhanh h∆°n nh∆∞ng k√©m ch√≠nh x√°c h∆°n)
```

### 3. Filter theo metadata

C√≥ th·ªÉ th√™m filter ƒë·ªÉ ch·ªâ t√¨m trong m·ªôt s·ªë files c·ª• th·ªÉ:

```python
# Trong rag_service_sql.py, th√™m parameter
def chat(self, query: str, top_k: int = 4, file_filter: List[str] = None):
    # ...
    if file_filter:
        sql += f" AND FileName IN ({','.join(['?' for _ in file_filter])})"
```

---

## üêõ Troubleshooting

### V·∫•n ƒë·ªÅ: Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan

**Nguy√™n nh√¢n:**
- Embeddings ch∆∞a ƒë∆∞·ª£c t·∫°o ƒë√∫ng
- Query kh√¥ng match v·ªõi content trong database
- Chunk_size qu√° l·ªõn, m·∫•t context

**Gi·∫£i ph√°p:**
- Ki·ªÉm tra embeddings c√≥ NULL kh√¥ng: `SELECT COUNT(*) FROM rag_documents WHERE Embedding IS NULL`
- Th·ª≠ query v·ªõi t·ª´ kh√≥a c·ª• th·ªÉ h∆°n
- Gi·∫£m chunk_size v√† ingest l·∫°i

### V·∫•n ƒë·ªÅ: C√¢u tr·∫£ l·ªùi kh√¥ng ch√≠nh x√°c

**Nguy√™n nh√¢n:**
- Top_k qu√° nh·ªè, thi·∫øu context
- LLM temperature qu√° cao (t·ª± b·ªãa ƒë·∫∑t)

**Gi·∫£i ph√°p:**
- TƒÉng top_k l√™n 6-8
- Gi·∫£m temperature xu·ªëng 0.3-0.5
- Ki·ªÉm tra similarity score (ch·ªâ l·∫•y > 0.7)

### V·∫•n ƒë·ªÅ: T·ªëc ƒë·ªô ch·∫≠m

**Nguy√™n nh√¢n:**
- Kh√¥ng c√≥ vector index
- Embedding dimension qu√° l·ªõn
- Qu√° nhi·ªÅu documents trong database

**Gi·∫£i ph√°p:**
- T·∫°o vector index (HNSW)
- Gi·∫£m embedding dimension n·∫øu c√≥ th·ªÉ
- Th√™m filter theo metadata ƒë·ªÉ gi·∫£m s·ªë l∆∞·ª£ng documents c·∫ßn search

---

## üìù T√≥m t·∫Øt

**ChatAI hi·ªÉu v√† truy xu·∫•t th√¥ng tin t·ª´ `rag_documents` qua 3 b∆∞·ªõc:**

1. **Ingest**: PDF ‚Üí Chunks ‚Üí Embeddings ‚Üí SQL Server
2. **Retrieval**: Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Top-K chunks
3. **Generation**: Context + Query ‚Üí LLM ‚Üí Answer + Sources

**ƒêi·ªÉm m·∫°nh:**
- ‚úÖ Semantic search (hi·ªÉu nghƒ©a, kh√¥ng ch·ªâ t·ª´ kh√≥a)
- ‚úÖ Context-aware (d·ª±a v√†o t√†i li·ªáu c·ª• th·ªÉ)
- ‚úÖ Traceable (c√≥ sources ƒë·ªÉ ki·ªÉm tra)

**C√¥ng ngh·ªá s·ª≠ d·ª•ng:**
- SQL Server 2025 VECTOR type
- VECTOR_DISTANCE function
- Google Gemini LLM
- LangChain framework

---

## üîó T√†i li·ªáu li√™n quan

- `README_RAG_SQL.md` - H∆∞·ªõng d·∫´n setup v√† s·ª≠ d·ª•ng RAG API
- `rag_service_sql.py` - Implementation chi ti·∫øt
- `rag_main_sql.py` - FastAPI endpoints
- `CREATE_RAG_TABLE.sql` - Schema database
